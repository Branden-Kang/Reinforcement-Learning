{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUlJxaesvQxytXHRCPq7WB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://medium.com/@theStump/how-to-beat-a-12-year-old-girl-in-battleship-using-transformers-with-reinforcement-learning-b506f7bea470)"
      ],
      "metadata": {
        "id": "MknMaRqmb9mJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "import numpy as np\n",
        "import numpy.typing as npt\n",
        "\n",
        "def place_ships(board_height:int=10,board_width:int=10,ship_sizes:List[int]=[2,3,3,4,5]) -> np.ndarray:\n",
        "    \"\"\" Return random ship positions.\"\"\"\n",
        "    board = np.zeros(shape=(board_width,board_height), dtype=np.float32)\n",
        "    board_size = board_width * board_height\n",
        "    def can_place_ship(x, y, length, direction):\n",
        "        \"\"\"Check if a ship can be placed at (x, y) in a given direction without overlapping.\"\"\"\n",
        "        if direction == \"H\":  # Horizontal\n",
        "            if y + length > board_height:\n",
        "                return False\n",
        "            return all(board[x, y+i] == 0 for i in range(length))\n",
        "        else:  # Vertical\n",
        "            if x + length > board_width:\n",
        "                return False\n",
        "            return all(board[x+i, y] == 0 for i in range(length))\n",
        "\n",
        "    def place_ship(x, y, length, direction):\n",
        "        \"\"\"Place a ship at (x, y) in a given direction.\"\"\"\n",
        "        for i in range(length):\n",
        "            if direction == \"H\":\n",
        "                board[x, y+i] = 1  # Mark ship presence\n",
        "            else:\n",
        "                board[x+i, y] = 1\n",
        "\n",
        "    for ship_size in ship_sizes:\n",
        "        placed = False\n",
        "        while not placed:\n",
        "            x, y = np.random.randint(0, board_width-1),np.random.randint(0, board_height-1)\n",
        "            direction = np.random.choice([\"H\", \"V\"])  # Horizontal or Vertical\n",
        "\n",
        "            if can_place_ship(x, y, ship_size, direction):\n",
        "                place_ship(x, y, ship_size, direction)\n",
        "                placed = True\n",
        "    return np.reshape(board, (1, board_size))\n",
        "\n",
        "def print_board(board: npt.NDArray, predicted_board: npt.NDArray = None):\n",
        "    \"\"\"Print the board with proper alignment.\"\"\"\n",
        "\n",
        "    cols = board.shape[1]  # Number of columns\n",
        "    col_width = 1  # Space for each number\n",
        "    separator = \" | \"  # Column separator\n",
        "\n",
        "    # Header row\n",
        "    column_numbers = \"     \" + separator.join(f\"{chr(65+i):{col_width}}\" for i in range(cols))\n",
        "    top_border = \"  \" + \"-\" * (cols * (col_width + 3) - 1)\n",
        "\n",
        "    if predicted_board is not None:\n",
        "        column_numbers += \"           \" + separator.join(f\"{chr(65+i):{col_width}}\" for i in range(predicted_board.shape[1]))\n",
        "        top_border += \"      \" + \"-\" * (predicted_board.shape[1] * (col_width + 3) - 1)\n",
        "    print(\"Current Board \\t\\t\\t\\t\\t Predicted Board\")\n",
        "    print(column_numbers)\n",
        "    print(top_border)\n",
        "\n",
        "    # Print board row by row\n",
        "    for i, row in enumerate(board):\n",
        "        row_str = f\"{i+1:{col_width+1}} | \" + separator.join(f\"{int(cell):{col_width}}\" for cell in row) + \" |\"\n",
        "        if predicted_board is not None:\n",
        "            row_p = predicted_board[i, :]\n",
        "            row_str += \"    \" + f\"{i+1:{col_width+1}} | \" + separator.join(f\"{int(cell):{col_width}}\" for cell in row_p) + \" |\"\n",
        "        print(row_str)\n"
      ],
      "metadata": {
        "id": "-vXoo2UZccQb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import math\n",
        "import copy\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        # Ensure that the model dimension (d_model) is divisible by the number of heads\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "\n",
        "        # Initialize dimensions\n",
        "        self.d_model = d_model # Model's dimension\n",
        "        self.num_heads = num_heads # Number of attention heads\n",
        "        self.d_k = d_model // num_heads # Dimension of each head's key, query, and value\n",
        "\n",
        "        # Linear layers for transforming inputs\n",
        "        self.W_q = nn.Linear(d_model, d_model) # Query transformation\n",
        "        self.W_k = nn.Linear(d_model, d_model) # Key transformation\n",
        "        self.W_v = nn.Linear(d_model, d_model) # Value transformation\n",
        "        self.W_o = nn.Linear(d_model, d_model) # Output transformation\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
        "        # Calculate attention scores\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "\n",
        "        # Apply mask if provided (useful for preventing attention to certain parts like padding)\n",
        "        if mask is not None:\n",
        "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        # Softmax is applied to obtain attention probabilities\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "\n",
        "        # Multiply by values to obtain the final output\n",
        "        output = torch.matmul(attn_probs, V)\n",
        "        return output\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        # Reshape the input to have num_heads for multi-head attention\n",
        "        batch_size, seq_length, d_model = x.size()\n",
        "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        # Combine the multiple heads back to original shape\n",
        "        batch_size, _, seq_length, d_k = x.size()\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        # Apply linear transformations and split heads\n",
        "        Q = self.split_heads(self.W_q(Q))\n",
        "        K = self.split_heads(self.W_k(K))\n",
        "        V = self.split_heads(self.W_v(V))\n",
        "\n",
        "        # Perform scaled dot-product attention\n",
        "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
        "\n",
        "        # Combine heads and apply output transformation\n",
        "        output = self.W_o(self.combine_heads(attn_output))\n",
        "        return output\n",
        "\n",
        "class PositionWiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(PositionWiseFeedForward, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.relu(self.fc1(x)))\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_seq_length):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        pe = torch.zeros(max_seq_length, d_model)\n",
        "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        attn_output = self.self_attn(x, x, x, mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm2(x + self.dropout(ff_output))\n",
        "        return x\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
        "        x = self.norm2(x + self.dropout(attn_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm3(x + self.dropout(ff_output))\n",
        "        return x\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        # nn.init.normal_(self.encoder_embedding.weight, mean=0, std=0.1)\n",
        "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model,padding_idx=0)\n",
        "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
        "\n",
        "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "\n",
        "        self.fc_decoder = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def encoder(self, src: torch.Tensor, src_mask: torch.Tensor = None):\n",
        "        \"\"\"Encoder only model\n",
        "\n",
        "        Args:\n",
        "            src (torch.Tensor): Input current map as a Tensor [batch, boardheight*boardwidth]\n",
        "            src_mask (torch.Tensor, optional): Mask for the input. Defaults to None.\n",
        "        Returns:\n",
        "            Tensor: Probabilities shaped [batch_size, boardheight*boardwidth]\n",
        "        \"\"\"\n",
        "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
        "        enc_output = src_embedded\n",
        "        for enc_layer in self.encoder_layers:\n",
        "            enc_output = enc_layer(enc_output, src_mask)\n",
        "        return enc_output\n",
        "\n",
        "    def decoder(self, enc_output,tgt, src_mask=None, tgt_mask=None):\n",
        "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
        "        dec_output = tgt_embedded\n",
        "        for dec_layer in self.decoder_layers:\n",
        "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
        "        output = self.fc_decoder(dec_output)\n",
        "        return output\n",
        "\n",
        "    def generate_mask(self, src, tgt):\n",
        "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
        "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
        "        seq_length = tgt.size(1)\n",
        "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
        "        tgt_mask = tgt_mask & nopeak_mask\n",
        "        return src_mask, tgt_mask\n",
        "\n",
        "\n",
        "    def generate_random_mask(self, src, tgt, p:float=0.15):\n",
        "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
        "        tgt_mask = (tgt != 1).unsqueeze(1).unsqueeze(3)\n",
        "\n",
        "        # Apply random masking\n",
        "        random_src_mask = (torch.rand_like(src_mask.float()) > p).bool()\n",
        "        random_tgt_mask = (torch.rand_like(tgt_mask.float()) > p).bool()\n",
        "\n",
        "        src_mask = src_mask & random_src_mask\n",
        "        tgt_mask = tgt_mask & random_tgt_mask\n",
        "\n",
        "        seq_length = tgt.size(1)\n",
        "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length,device=tgt.device), diagonal=1)).bool()\n",
        "        tgt_mask = tgt_mask & nopeak_mask\n",
        "\n",
        "        return src_mask, tgt_mask\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask = None; tgt_mask = None\n",
        "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
        "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
        "\n",
        "        enc_output = src_embedded\n",
        "        for enc_layer in self.encoder_layers:\n",
        "            enc_output = enc_layer(enc_output, src_mask)\n",
        "\n",
        "        dec_output = tgt_embedded\n",
        "        for dec_layer in self.decoder_layers:\n",
        "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "        output = self.fc_decoder(dec_output)\n",
        "        return output"
      ],
      "metadata": {
        "id": "so_-weXIcipc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "    Board values: -1 for no guesses, 0 bomb, 1 for hit\n",
        "'''\n",
        "\n",
        "from typing import List, Tuple\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch, os\n",
        "from torch import Tensor\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os.path as osp\n",
        "from tqdm import trange,tqdm\n",
        "import numpy.typing as npt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "torch.cuda.empty_cache()\n",
        "SHIP_SIZES = [2,3,3,4,5]\n",
        "board_height = 10\n",
        "board_width = 10\n",
        "\n",
        "\n",
        "def generate_game_data(nboards:int,board_height:int,board_width:int,ship_sizes:List[int]) -> Tuple[npt.NDArray,npt.NDArray]:\n",
        "    \"\"\"Generates dummy game data for training\n",
        "\n",
        "    Args:\n",
        "        nboards (int): number boards to generate\n",
        "        board_height (int): board height in units\n",
        "        board_width (int): board width in units\n",
        "        ship_sizes (List[int]): Array of ship sizes e.g. [2,3,3,4,5]\n",
        "        src_blank (float): percent of source board to blank out\n",
        "\n",
        "    Returns:\n",
        "        Tuple[npt.NDArray,npt.NDArray]: source, target\n",
        "    \"\"\"\n",
        "    percent_of_src_to_generate = 0.10\n",
        "    number_of_guesses = int(board_height * board_width*(1-percent_of_src_to_generate))\n",
        "    src_board = np.zeros((nboards*number_of_guesses,board_height*board_width))\n",
        "    tgt_board = np.zeros((nboards*number_of_guesses,board_height*board_width))\n",
        "    for indx in trange(nboards):\n",
        "        ship_positions = place_ships(board_height,board_width,ship_sizes)\n",
        "        ship_position_indices = np.where(ship_positions == 1)[1]\n",
        "        bomb_locations = np.arange(board_height*board_width)\n",
        "        for guess in range(number_of_guesses):\n",
        "            tgt_board[indx*number_of_guesses+guess,:] = 2*(ship_positions  == 1) + 1*(ship_positions == 0)\n",
        "\n",
        "        for p in range(board_height*board_width-number_of_guesses): # Lets guess 15 % of the board before we begin training\n",
        "            bomb_index = np.random.choice(bomb_locations)\n",
        "            src_board[indx*number_of_guesses,bomb_index] = 2 * (bomb_index in ship_position_indices) + 1 * (bomb_index not in ship_position_indices)\n",
        "            bomb_locations = np.delete(bomb_locations, np.where(bomb_locations == bomb_index))\n",
        "\n",
        "        for guess in range(1,number_of_guesses):\n",
        "            src_board[indx*number_of_guesses+guess,:] = src_board[indx*number_of_guesses+guess-1,:]\n",
        "            bomb_index = np.random.choice(bomb_locations)\n",
        "            src_board[indx*number_of_guesses+guess,bomb_index] = 2 * (bomb_index in ship_position_indices) + 1 * (bomb_index not in ship_position_indices)\n",
        "            bomb_locations = np.delete(bomb_locations, np.where(bomb_locations == bomb_index))\n",
        "\n",
        "    return src_board,tgt_board\n",
        "\n",
        "def generate_square_subsequent_mask(size):\n",
        "    mask = torch.triu(torch.ones(size, size), diagonal=1)  # Upper triangular mask\n",
        "    mask = mask.masked_fill(mask == 1, float('-inf'))\n",
        "    return mask\n",
        "\n",
        "def apply_random_mask(tgt: torch.Tensor, mask_token: int = 0, mask_prob: float = 0.15):\n",
        "    masked_tgt = tgt.clone()\n",
        "    labels = tgt.clone()\n",
        "\n",
        "    # Create random mask\n",
        "    mask = torch.rand(tgt.shape, device=tgt.device) < mask_prob\n",
        "\n",
        "    # Replace input with mask token\n",
        "    masked_tgt[mask] = mask_token\n",
        "\n",
        "    # Optionally, ignore loss on unmasked tokens using ignore_index\n",
        "    loss_mask = mask  # use this to mask the loss later\n",
        "\n",
        "    return masked_tgt, labels, loss_mask\n",
        "\n",
        "def generate_games(ngames:int=2000,board_height:int=10,board_width:int=10,ship_sizes:List[int]=SHIP_SIZES):\n",
        "    \"\"\"Generate Games\n",
        "\n",
        "    Args:\n",
        "        ngames (int, optional): number of games to generate. Defaults to 2000.\n",
        "        board_height (int, optional): board height. Defaults to 10.\n",
        "        board_width (int, optional): board width. Defaults to 10.\n",
        "        ship_sizes (List[int], optional): ship sizes to use. Defaults to SHIP_SIZES.\n",
        "    \"\"\"\n",
        "    print(\"Generating Games to play\")\n",
        "    src,tgt = generate_game_data(ngames,board_height,board_width,SHIP_SIZES)\n",
        "\n",
        "    os.makedirs('data',exist_ok=True)\n",
        "    data = {'src':src,'tgt':tgt}\n",
        "    pickle.dump(data,open('data/training_data.pickle','wb'))\n",
        "\n",
        "\n",
        "def load_model():\n",
        "    path = 'data'\n",
        "    files = [\n",
        "        os.path.join(path, f)\n",
        "        for f in os.listdir(path)\n",
        "        if f.endswith('.pth') and os.path.isfile(os.path.join(path, f))\n",
        "    ]\n",
        "    filename = max(files, key=os.path.getmtime)\n",
        "\n",
        "    data = torch.load(filename,map_location=device)\n",
        "\n",
        "    model = Transformer(src_vocab_size=data['model']['src_vocab_size'],\n",
        "                        tgt_vocab_size=data['model']['tgt_vocab_size'],\n",
        "                        d_model=data['model']['d_model'],\n",
        "                        num_heads=data['model']['num_heads'],\n",
        "                        num_layers=data['model']['num_layers'],\n",
        "                        d_ff=data['model']['d_ff'],\n",
        "                        max_seq_length=data['model']['max_seq_length'],\n",
        "                        dropout=data['model']['dropout']).to(device)\n",
        "\n",
        "    model.load_state_dict(data['model']['state_dict'])\n",
        "    model.eval()\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
        "    optimizer.load_state_dict(data['optimizer'])\n",
        "    try:\n",
        "        epochs = data['model']['epochs']\n",
        "    except:\n",
        "        epochs = 0\n",
        "    print(f\"Loaded model with {epochs} epochs\")\n",
        "    return model,optimizer,epochs,data\n",
        "\n",
        "def train(resume_training:bool=False,save_every_n_epoch:int=10,epochs:int=100):\n",
        "    \"\"\"This function will train the model using the data generated by generate_game_data.\n",
        "\n",
        "    Args:\n",
        "        resume_training (bool, optional): Resume training. Defaults to False.\n",
        "        save_every_n_epoch (int, optional): Save every n epochs. Defaults to 10.\n",
        "    \"\"\"\n",
        "    src_vocab_size = 3\n",
        "    tgt_vocab_size = 3 # 0, 1, 2\n",
        "    d_model = 512\n",
        "    num_heads = 4\n",
        "    num_layers = 4\n",
        "    d_ff = 2048\n",
        "    max_seq_length = board_height*board_width\n",
        "    dropout = 0.1\n",
        "    # Instantiate model\n",
        "    model = Transformer(src_vocab_size=src_vocab_size,\n",
        "                        tgt_vocab_size=tgt_vocab_size,\n",
        "                        d_model=d_model, num_heads=num_heads, num_layers=num_layers,\n",
        "                        d_ff=d_ff,\n",
        "                        max_seq_length=max_seq_length, dropout=dropout).to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.01)\n",
        "    # optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.98), eps=1e-9)\n",
        "    # optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "    if (not osp.exists(\"data/training_data.pickle\")):\n",
        "        generate_games(ngames=20000,board_height=board_height,board_width=board_width,ship_sizes=SHIP_SIZES)\n",
        "\n",
        "    data = pickle.load(open('data/training_data.pickle','rb'))\n",
        "\n",
        "    if resume_training:\n",
        "        model,optimizer,current_epochs,_ = load_model()\n",
        "    else:\n",
        "        current_epochs = 0\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "    scaler = GradScaler(device=device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.01)\n",
        "\n",
        "\n",
        "    def train_loop(src:npt.NDArray,tgt:npt.NDArray):\n",
        "        # Train the model\n",
        "        src_train, src_test, tgt_train, tgt_test = train_test_split(src, tgt, test_size=0.3,shuffle=True)\n",
        "        src_train_tensor = torch.tensor(src_train, dtype=torch.long)\n",
        "        tgt_train_tensor = torch.tensor(tgt_train, dtype=torch.long)\n",
        "        src_test_tensor = torch.tensor(src_test, dtype=torch.long)\n",
        "        tgt_test_tensor = torch.tensor(tgt_test, dtype=torch.long)\n",
        "\n",
        "        train_dataset = TensorDataset(src_train_tensor, tgt_train_tensor)       # Create a dataset\n",
        "        test_dataset = TensorDataset(src_test_tensor, tgt_test_tensor)       # Create a dataset\n",
        "\n",
        "        batch_size = 128\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        # Calculate class weights (adjust manually if needed)\n",
        "        all_targets = tgt_train_tensor.view(-1)\n",
        "        class_counts = torch.bincount(all_targets, minlength=3).float()\n",
        "        class_weights = 1.0 / (class_counts + 1e-6)\n",
        "        class_weights = class_weights / class_weights.sum()\n",
        "        class_weights = class_weights.to(device)\n",
        "        criterion_train = nn.CrossEntropyLoss(weight=class_weights,ignore_index=0)\n",
        "\n",
        "        all_targets = tgt_test_tensor.view(-1)\n",
        "        class_counts = torch.bincount(all_targets, minlength=3).float()\n",
        "        class_weights = 1.0 / (class_counts + 1e-6)\n",
        "        class_weights = class_weights / class_weights.sum()\n",
        "        class_weights = class_weights.to(device)\n",
        "        criterion_val = nn.CrossEntropyLoss(weight=class_weights,ignore_index=0)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            model.train()\n",
        "            pbar = tqdm(train_loader)\n",
        "            for batch in pbar:\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                src_batch, tgt_batch = batch\n",
        "                src_batch = src_batch.to(device)\n",
        "                tgt_batch = tgt_batch.to(device)\n",
        "\n",
        "                guessed_mask = (tgt_batch != 0)\n",
        "                random_mask = (torch.rand_like(tgt_batch.float()) > 0.9).to(device)\n",
        "                final_mask = guessed_mask & random_mask\n",
        "                tgt_batch_masked = tgt_batch.clone()\n",
        "                tgt_batch_masked[~final_mask] = 0\n",
        "                with autocast(device_type='cuda', dtype=torch.float16):\n",
        "                    output = model(src_batch, tgt_batch_masked)\n",
        "                    loss = criterion_train(output.view(-1, tgt_vocab_size), tgt_batch.view(-1))\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "\n",
        "                output_tokens = output.argmax(dim=-1)\n",
        "                hits = torch.sum(output_tokens == 2).detach().cpu()\n",
        "                matches = torch.sum(output_tokens == tgt_batch).detach().cpu()\n",
        "                # print(torch.sum(matches))\n",
        "                pbar.set_description(f\"Epoch: {epoch+current_epochs:d} Train Loss: {loss.item():0.2e} Hits match {hits/batch_size:0.2f} Matches {matches/batch_size:0.2f}\")\n",
        "\n",
        "\n",
        "            pbar = tqdm(test_loader)\n",
        "            total_val_loss = 0; num_batches = 0\n",
        "            model.eval()\n",
        "            for batch in pbar:\n",
        "                src_batch, tgt_batch = batch\n",
        "                src_batch = src_batch.to(device)\n",
        "                tgt_batch = tgt_batch.to(device)\n",
        "\n",
        "                output = model(src_batch, tgt_batch)\n",
        "                val_loss = criterion_val(output.view(-1, tgt_vocab_size), tgt_batch.view(-1))\n",
        "\n",
        "                pred_classes = output.argmax(dim=-1)\n",
        "                # print(src_batch[0,:])\n",
        "                # print(pred_classes[0,:])\n",
        "\n",
        "                total_val_loss += val_loss.item()\n",
        "                num_batches += 1\n",
        "                pbar.set_description(f\"Epoch: {epoch+current_epochs:d} Train Loss: {loss.item():0.2e} Val Loss: {val_loss.item():0.2e}\")\n",
        "            average_val_loss = total_val_loss / num_batches  # Compute average validation loss\n",
        "            pbar.set_description(f\"Epoch: {epoch+current_epochs:d} Train Loss: {loss.item():0.2e} Val Loss: {average_val_loss:0.2e}\")\n",
        "            scheduler.step()\n",
        "            if (epoch % save_every_n_epoch == 0) or (epoch == epochs-1):\n",
        "                # Save the model\n",
        "                data = dict()\n",
        "                data['model'] = {\n",
        "                    'state_dict': model.state_dict(),\n",
        "                    'src_vocab_size': src_vocab_size,\n",
        "                    'tgt_vocab_size': tgt_vocab_size,\n",
        "                    'd_model': d_model,\n",
        "                    'num_heads': num_heads,\n",
        "                    'num_layers': num_layers,\n",
        "                    'd_ff': d_ff,\n",
        "                    'max_seq_length': max_seq_length,\n",
        "                    'dropout': dropout,\n",
        "                    'epochs':epoch+current_epochs\n",
        "                }\n",
        "                data['optimizer'] = optimizer.state_dict()\n",
        "                torch.save(data, f\"data/trained_model-{epoch+current_epochs}.pth\")\n",
        "                if not resume_training:\n",
        "                    torch.save(data, \"data/trained_model.bak.pth\")\n",
        "                print(f\"Saved model at epoch {epoch+current_epochs}\")\n",
        "\n",
        "    model.to(device)\n",
        "    src = data['src']\n",
        "    tgt = data['tgt']\n",
        "\n",
        "    print(\"Train Loop\")\n",
        "    train_loop(src,tgt)\n",
        "\n",
        "# if __name__ ==\"__main__\":\n",
        "    # generate_games(10000,board_height,board_width,SHIP_SIZES)\n",
        "    # train(resume_training=True)"
      ],
      "metadata": {
        "id": "dAA0uCELcSob"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "import torch\n",
        "import numpy as np\n",
        "import numpy.typing as npt\n",
        "from tqdm import trange\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "\n",
        "# tgt_start = torch.tensor([[start_token]])  # Start decoding with \"<SOS>\"\n",
        "# output = transformer(src, tgt_start)  # First decoder step\n",
        "\n",
        "# for _ in range(max_len):  # Generate tokens until \"<EOS>\" appears\n",
        "#     next_token = output[:, -1]  # Get last generated token\n",
        "#     tgt_start = torch.cat([tgt_start, next_token], dim=1)  # Append new token\n",
        "#     output = transformer(src, tgt_start)  # Decode again\n",
        "#     if next_token == eos_token:\n",
        "#         break\n",
        "\n",
        "def bomb_index_to_human_readable(bomb_index:int,board_width:int)->str:\n",
        "    \"\"\"Convert bomb index to human-readable format\"\"\"\n",
        "    row = bomb_index // board_width\n",
        "    col = int(bomb_index - row * board_width)\n",
        "    # convert col to letter\n",
        "    row_str = chr(col+65)\n",
        "    return f\"{row_str}-{row+1}\"\n",
        "\n",
        "def human_readable_to_bomb_index(human_readable:str, board_width:int) -> int:\n",
        "    \"\"\"Convert human-readable format to bomb index\"\"\"\n",
        "\n",
        "    # Split the input string into row and column parts\n",
        "    col_str, row_str = human_readable.split('-')\n",
        "\n",
        "    # Convert the row letter (e.g. 'J') to a column index\n",
        "    col = ord(col_str.upper()) - 65\n",
        "\n",
        "    # Convert the row number (e.g. '2') to a zero-based index\n",
        "    row = int(row_str) - 1\n",
        "\n",
        "    # Calculate the bomb index from row and column\n",
        "    bomb_index = row * board_width + col\n",
        "    return bomb_index\n",
        "\n",
        "def run_inference(model:torch.nn.Module,current_board:torch.Tensor)->str:\n",
        "    board_width  = current_board.shape[0]\n",
        "    board_length = current_board.shape[1]\n",
        "\n",
        "    board_size = current_board.shape[0]*current_board.shape[1]\n",
        "    current_board = torch.tensor(current_board, dtype=torch.long).to(device)\n",
        "    current_board = torch.reshape(current_board, (1, board_size)).to(device)\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation for speedup\n",
        "        memory = model.encoder(current_board)\n",
        "        output = current_board.clone()\n",
        "        output = model.decoder(memory, output)\n",
        "        output = torch.argmax(output, dim=-1)  # Shape: (batch_size, seq_length)\n",
        "    predicted_token_ids = output.cpu().numpy()\n",
        "\n",
        "    bomb_indices = np.where(predicted_token_ids==2)[1]\n",
        "    # Convert prediction back to matrix\n",
        "    return bomb_indices,predicted_token_ids.reshape((board_length,board_width))\n",
        "\n",
        "def ai_helper():\n",
        "    \"\"\"AI helps you win\n",
        "    \"\"\"\n",
        "    ship_sizes = [2,3,3,4,5]\n",
        "    board_height = 10\n",
        "    board_width = 10\n",
        "    model,_,_,_ = load_model()\n",
        "    percent_of_board_to_guess = 0.15\n",
        "\n",
        "    hits = 0\n",
        "    guesses = 0\n",
        "    past_predictions = list()\n",
        "    current_board = np.zeros(shape=(1,board_height*board_width), dtype=np.int64)  # 0 no bomb, 1 bomb, 2 hit\n",
        "    bomb_guesses = np.arange(board_height*board_width)\n",
        "\n",
        "    while guesses < board_height*board_width and hits < sum(ship_sizes):\n",
        "        if guesses < board_width*board_height*percent_of_board_to_guess:\n",
        "            bomb_index = np.random.choice(bomb_guesses)\n",
        "        else:\n",
        "            bomb_locations,predicted_board = run_inference(model,torch.tensor(current_board))\n",
        "            print_board(current_board.reshape(board_height,board_width),predicted_board.reshape(board_height,board_width))\n",
        "            for p in past_predictions:\n",
        "                bomb_locations = np.delete(bomb_locations, np.where(bomb_locations == p))\n",
        "            if len(bomb_locations) == 0:\n",
        "                bomb_index = np.random.randint(0,board_height*board_width-1)\n",
        "                print(\"No more bomb locations, making a random guess\")\n",
        "            else:\n",
        "                bomb_index = np.random.choice(bomb_locations)\n",
        "\n",
        "        human_readable_bomb_index = bomb_index_to_human_readable(bomb_index,board_width)\n",
        "        bomb_guesses = np.delete(bomb_guesses, np.where(bomb_guesses == bomb_index))\n",
        "        past_predictions.append(bomb_index)\n",
        "\n",
        "        # Loop until the user enters a valid input\n",
        "        while True:\n",
        "            print(f\"AI Guess: {human_readable_bomb_index}\")\n",
        "            guess = input(\"Enter guess or hit [Enter] for AI Guess: \").lower()\n",
        "            if guess == \"\":\n",
        "                guess = human_readable_bomb_index\n",
        "            else:\n",
        "                guess = guess.upper()\n",
        "            bomb_index = human_readable_to_bomb_index(guess,board_width)\n",
        "\n",
        "            hit = input(\"Hit (y) or (n): \").lower()  # Convert to lowercase for consistency\n",
        "\n",
        "            if hit == 'y' or hit == 'n':\n",
        "                hit = 1 if hit == 'y' else 0\n",
        "                # Update board\n",
        "                if hit == 1:\n",
        "                    current_board[0, bomb_index] = 2\n",
        "                    hits += 1\n",
        "                else:\n",
        "                    current_board[0, bomb_index] = 1\n",
        "                break  # Exit the loop once a valid input is entered\n",
        "            else:\n",
        "                print(\"Invalid input. Please enter 'y' for hit or 'n' for miss.\")\n",
        "        current_board[0,bomb_index] = 2 if hit else 1\n",
        "        guesses += 1\n",
        "\n",
        "def auto_game(n_games:int=1,train:bool=False):\n",
        "    ship_sizes = [2,3,3,4,5]\n",
        "    board_height = 10\n",
        "    board_width = 10\n",
        "    model,optimizer,_,data = load_model()\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = 1e-4\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "    model = model.to(device)\n",
        "    pbar = trange(n_games)\n",
        "    for game in pbar:\n",
        "        hits = 0\n",
        "        bomb_index = -1\n",
        "        past_predictions = [-1]\n",
        "        guesses = 0\n",
        "        ship_positions = place_ships(board_height,board_width,ship_sizes)\n",
        "        ship_position_indices = np.where(ship_positions == 1)[1]\n",
        "        bomb_guesses = np.arange(board_height*board_width)\n",
        "\n",
        "        hit_or_miss = \"\"\n",
        "        if n_games==1:\n",
        "            print(\"Ship positions:\")\n",
        "            print_board(ship_positions.reshape(board_height,board_width))\n",
        "\n",
        "        if train:\n",
        "            ships = sum(ship_sizes)\n",
        "            no_ships = board_height*board_width - ships\n",
        "            class_counts = torch.tensor([0, no_ships, ships])\n",
        "            class_weights = 1.0 / (class_counts + 1e-6)\n",
        "            class_weights = class_weights / class_weights.sum()\n",
        "            class_weights = class_weights.to(device)\n",
        "            criterion = torch.nn.CrossEntropyLoss(weight=class_weights,ignore_index=0)\n",
        "            tgt_vocab_size = 3\n",
        "        # 0 no bomb, 1 bomb, 2 hit\n",
        "        # Store all the games played\n",
        "        games = np.zeros(shape=(board_height*board_width, board_height, board_width), dtype=np.int64)\n",
        "        game_index = 0\n",
        "        percent_of_board_to_guess = 0.15\n",
        "        current_board = torch.from_numpy(np.zeros(shape=(board_height,board_width), dtype=np.int64)).type(torch.long)  # 0 no bomb, 1 bomb, 2 hit\n",
        "\n",
        "        while guesses < board_height*board_width and hits < sum(ship_sizes):\n",
        "            # Make the guess\n",
        "            if guesses < board_width*board_height*percent_of_board_to_guess:\n",
        "                bomb_index = np.random.choice(bomb_guesses)\n",
        "            else:\n",
        "                bomb_locations,predicted_board = run_inference(model,current_board)\n",
        "                for p in past_predictions:\n",
        "                    bomb_locations = np.delete(bomb_locations, np.where(bomb_locations == p))\n",
        "                if len(bomb_locations) == 0:\n",
        "                    bomb_index = np.random.randint(0,board_height*board_width-1)\n",
        "                    print(\"No more bomb locations, making a random guess\")\n",
        "                else:\n",
        "                    bomb_index = np.random.choice(bomb_locations)\n",
        "\n",
        "            human_readable_bomb_index = bomb_index_to_human_readable(bomb_index,board_width)\n",
        "            # Test the guess\n",
        "            current_board = current_board.reshape((1,board_height*board_width)).to(device)\n",
        "            current_board[0,bomb_index] = 2 * (bomb_index in ship_position_indices) + 1 * (bomb_index not in ship_position_indices)  # 0 no bomb, 1 bomb, 2 hit\n",
        "\n",
        "            if (current_board[0,bomb_index] == 2):\n",
        "                hit_or_miss = \"hit\"\n",
        "                hits += 1\n",
        "            else:\n",
        "                hit_or_miss = \"miss\"\n",
        "            current_board = current_board.reshape((board_height,board_width))\n",
        "\n",
        "            if n_games==1:\n",
        "                print(f\"\\nGuessed {guesses} human_readable_bomb_index {human_readable_bomb_index} bomb_index {bomb_index} {hit_or_miss}\")\n",
        "                if guesses < board_width*board_height*percent_of_board_to_guess:\n",
        "                    print_board(current_board)\n",
        "                else:\n",
        "                    print_board(current_board, predicted_board)\n",
        "\n",
        "            bomb_guesses = np.delete(bomb_guesses, np.where(bomb_guesses == bomb_index))\n",
        "            past_predictions.append(bomb_index)\n",
        "            if guesses > board_width*board_height*percent_of_board_to_guess:\n",
        "                games[game_index,:,:] = current_board.detach().cpu().numpy()\n",
        "                game_index+=1\n",
        "            guesses += 1\n",
        "\n",
        "        if n_games==1:\n",
        "            print(f\"total hits {hits}\")\n",
        "            print_board(current_board.reshape(board_height,board_width))\n",
        "\n",
        "        if train: # Train the board on the game it just played\n",
        "            src = torch.tensor(games[:game_index-1,:,:]).reshape(game_index-1,board_height*board_width).to(device)\n",
        "            tgt = src.clone()\n",
        "            tgt[:,:] = torch.where(current_board == 0, torch.tensor(1), current_board).reshape(1,board_height*board_width).to(device)\n",
        "\n",
        "            print(f'Training on {game_index-1} games')\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            output = model(src,tgt)\n",
        "            loss = criterion(output.contiguous().view(-1, tgt_vocab_size), tgt.view(-1).contiguous().long())  # Convert to long\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if (game%50 == 0):\n",
        "                scheduler.step()\n",
        "    if train: # Save the model state as auto_game\n",
        "        print(f'Train Loss: {loss.item():0.2e}')\n",
        "        data['model']['state_dict'] = model.state_dict()\n",
        "        data['optimizer'] = optimizer.state_dict()\n",
        "        torch.save(data, \"data/trained_model_auto_game.pth\")\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    ai_helper()\n",
        "    # auto_game(n_games=1000, train=True)\n",
        "    # auto_game(n_games=1,train=False)\n",
        ""
      ],
      "metadata": {
        "id": "aJsf62FrcS8u"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}